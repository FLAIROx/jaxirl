import flax.linen as flax_nn

HOPPER_IRL_CONFIG = {
    "log_gen_every": 1000,
    "reward_net_hsize": [128, 128],
    "reward_net_sigmoid": False,
    "wandb_log": True,
    "plot": False,
    "train_rng": "SAME",
    "save_to_file": False,
    "reward_type": "REWARD_STATE",
    "reward_normalize": True,
    "real_reward_type": "IRL_STATE",
    "loss": "IRL",
    "discr_batch_size": 4096,
    "seed": 1,
    "seeds": 5,
    "num_eval_envs": 20,
    "irl_lrate_init": 1e-2,
    "inner_lr_linear": True,
    "inner_lr": 4e-4,
    "inner_steps": 15,
    "discr_trans_decay": 1000,
    "discr_updates_every": 1,
    "discr_updates": 15,
    "discr_l1_loss": 0.0,
    "dual": False,
    "discr_schedule_type": "linear",
    "discr_final_lr": 1e-5,
    "run_test": False,
    "discr_loss": "bce",
    "num_updates_inner_loop": 1,
    "buffer_size": 400000,
}

ANT_IRL_CONFIG = {
    "log_gen_every": 1000,
    "reward_net_hsize": [128, 128],
    "reward_net_sigmoid": False,
    "wandb_log": True,
    "plot": False,
    "train_rng": "SAME",
    "save_to_file": False,
    "reward_type": "REWARD_STATE",
    "reward_normalize": True,
    "real_reward_type": "IRL_STATE",
    "loss": "IRL",
    "discr_batch_size": 4096,
    "seed": 1,
    "seeds": 5,
    "num_eval_envs": 20,
    "irl_lrate_init": 1e-2,
    "inner_lr_linear": True,
    "inner_lr": 4e-4,
    "inner_steps": 15,
    "discr_trans_decay": 1000,
    "discr_updates_every": 1,
    "discr_updates": 15,
    "discr_l1_loss": 0.0,
    "dual": False,
    "discr_schedule_type": "linear",
    "discr_final_lr": 1e-5,
    "run_test": False,
    "discr_loss": "bce",
    "num_updates_inner_loop": 1,
    "buffer_size": 400000,
}

WALKER_IRL_CONFIG = {
    "log_gen_every": 1000,
    "reward_net_hsize": [128, 128],
    "reward_net_sigmoid": False,
    "wandb_log": True,
    "plot": False,
    "train_rng": "SAME",
    "save_to_file": False,
    "reward_type": "REWARD_STATE",
    "reward_normalize": True,
    "real_reward_type": "IRL_STATE",
    "loss": "IRL",
    "discr_batch_size": 4096,
    "seed": 1,
    "seeds": 5,
    "num_eval_envs": 20,
    "irl_lrate_init": 1e-2,
    "inner_lr_linear": True,
    "inner_lr": 4e-4,
    "inner_steps": 15,
    "discr_trans_decay": 800,
    "discr_updates_every": 1,
    "discr_updates": 15,
    "discr_l1_loss": 0.0,
    "dual": False,
    "discr_schedule_type": "linear",
    "discr_final_lr": 1e-5,
    "run_test": False,
    "discr_loss": "bce",
    "num_updates_inner_loop": 1,
    "buffer_size": 400000,
}


HALFCHEETAH_IRL_CONFIG = {
    "log_gen_every": 1000,
    "reward_net_hsize": [128, 128],
    "reward_net_sigmoid": False,
    "wandb_log": True,
    "plot": False,
    "train_rng": "SAME",
    "save_to_file": False,
    "reward_type": "REWARD_STATE",
    "reward_normalize": True,
    "real_reward_type": "IRL_STATE",
    "loss": "IRL",
    "discr_batch_size": 4096,
    "seed": 1,
    "seeds": 5,
    "num_eval_envs": 20,
    "irl_lrate_init": 1e-4,
    "inner_lr_linear": True,
    "inner_lr": 4e-4,
    "inner_steps": 15,
    "discr_trans_decay": 600,
    "discr_updates_every": 1,
    "discr_updates": 15,
    "discr_l1_loss": 0.0,
    "dual": False,
    "discr_schedule_type": "constant",
    "discr_final_lr": 1e-6,
    "run_test": False,
    "discr_loss": "bce",
    "num_updates_inner_loop": 1,
    "buffer_size": 400000,
}
